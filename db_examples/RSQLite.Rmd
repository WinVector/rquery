---
output: github_document
---


Let's work a non-trivial example: the `dplyr` pipeline 
from [Letâ€™s Have Some Sympathy For The Part-time R User](http://www.win-vector.com/blog/2017/08/lets-have-some-sympathy-for-the-part-time-r-user/).

For `RSQlite` this is going to be a mess, as we do not have window functions and self-joins can be problematic in `RSQlite`.



```{r ex, warning=FALSE, message=FALSE}
library("rquery")
library("wrapr")

raw_connection <- DBI::dbConnect(RSQLite::SQLite(), ":memory:")
RSQLite::initExtension(raw_connection)
db <- rquery_db_info(
  connection = raw_connection,
  is_dbi = TRUE,
  connection_options = rq_connection_tests(raw_connection))

# RSQLite has a non-standard modulo operator
db$expr_map[["MOD"]] <- list(pre_sql_token("("),
                           3,
                           pre_sql_token("%"),
                           5,
                           pre_sql_token(")"))


tmps <- mk_tmp_name_source("ex")


# copy data in so we have an example
d_local <- build_frame(
   "subjectID", "surveyCategory"     , "assessmentTotal", "irrelevantCol1", "irrelevantCol2" |
   1L         , "withdrawal behavior", 5                , "irrel1"        , "irrel2"         |
   1L         , "positive re-framing", 2                , "irrel1"        , "irrel2"         |
   2L         , "withdrawal behavior", 3                , "irrel1"        , "irrel2"         |
   2L         , "positive re-framing", 4                , "irrel1"        , "irrel2"         )
rq_copy_to(db, 'd',
            d_local,
            temporary = TRUE, 
            overwrite = TRUE)

# produce a hande to existing table
d <- db_td(db, "d")
```



```{r calcm, warning=FALSE, message=FALSE}

collector <- make_relop_list(tmps)

scale <- 0.237

# convert assessmentTotal to unscaled proabilities
dqp <- d %.>%
  extend(.,
         probability :=
           exp(assessmentTotal * scale)) %.>%
  collector

# total the probabilities per-group
dqs <- dqp %.>%
  project(., 
          tot_prob := sum(probability),
          groupby = 'subjectID') # could add a collector here to
                                 # to avoid a self-join if RSQlite
                                 # has a problem with that

# join total back in and scale
dqx <- natural_join(dqp, dqs,
                    by = 'subjectID',
                    jointype = 'LEFT') %.>%
  extend(., 
         probability := probability/tot_prob) %.>%
  collector

# find largest per subject probability
mp <- dqx %.>%
  project(., 
          probability := max(probability),
          groupby = 'subjectID') # could add a collector here to
                                 # to avoid a self-join if RSQlite
                                 # has a problem with that

# join in by best score and probability per subject 
# (to break ties)
# and finish the scoring as before
natural_join(mp, dqx,
                   by = c("subjectID", "probability")) %.>%
  project(., 
          probability := max(probability), # pseudo aggregator
          surveyCategory := min(surveyCategory),
          groupby = 'subjectID') %.>%
  rename_columns(., 'diagnosis' := 'surveyCategory') %.>%
  select_columns(., c('subjectID', 
                      'diagnosis', 
                      'probability')) %.>%
  orderby(., cols = 'subjectID') %.>% 
  collector
```

We then build our result.

```{r materialize, warning=FALSE, message=FALSE}
result <- collector %.>% db
```


And take a look.

```{r res, warning=FALSE, message=FALSE}
class(result)
result

DBI::dbReadTable(db$connection, result$table_name) %.>%
  knitr::kable(.)
```

`rqdatatable` can also execute collected operations.

```{r rqdt}
library("rqdatatable")

rqdatatable::ex_data_table(collector, tables = list(d = d_local))
```


We can also diagram the calculation.

```{r}
c(get_relop_list_stages(collector), list(result)) %.>%
  op_diagram(., merge_tables = TRUE, show_table_columns = FALSE) %.>% 
  DiagrammeR::grViz(.) %.>%
  DiagrammeRsvg::export_svg(.) %.>%
  write(., file="RSQLite_diagram.svg")
```

![](RSQLite_diagram.svg)

We can print the stages.

```{r printops}
collector
```

Or even print the enormous SQL required to implement the calculation.

```{r printsql}
for(stage in get_relop_list_stages(collector)) {
  cat(paste0("\n-- ", stage$materialize_as, "\n"))
  cat(paste0(to_sql(stage, db), ";\n\n"))
}
```

Notice how each stage was limited to columns actually used in later stages.

Some more discussion of the query explosion effect is available [here](https://github.com/WinVector/rquery/blob/master/extras/query_growth/query_growth.md).
Some timings of the query explosing effect are available [here](https://github.com/WinVector/rquery/blob/master/extras/query_growth/time_dag.md).


```{r cleanup}
# clean up tmps
intermediates <- tmps(dumpList = TRUE)
for(ti in intermediates) {
  rquery::rq_remove_table(db, ti)
}

DBI::dbDisconnect(raw_connection)
rm(list = c("raw_connection", "db"))
```
